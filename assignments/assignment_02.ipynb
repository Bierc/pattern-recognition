{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "177c62d3",
   "metadata": {},
   "source": [
    "\n",
    "The goal is to predict whether or not a passenger survived the Titanic challenge on Kaggle, based on attributes such as age, gender, passenger class, where they boarded, and so on.\n",
    "\n",
    "- First, log in to Kaggle and go to the Titanic challenge to download train.csv and test.csv. The data is already split into a training set and a test set. However, the test data does not contain the labels: your goal is to train the best possible model using the training data, so make your predictions on the test data and upload it to Kaggle to see your final score.\n",
    "\n",
    "- Then, evaluate the attributes of the training set. Some attributes contain missing data. This indicates that it may be unnecessary to include them in the model.\n",
    "\n",
    "- Next, evaluate the performance of some models seen in class.\n",
    "\n",
    "- To improve this result, you can:\n",
    "    - Compare more models and tune hyperparameters;\n",
    "    - Do some preprocessing on the features, for example:\n",
    "    - replace SibSp and Parch by their sum,\n",
    "    - try to identify parts of names that correlate well with the Survived attribute (for example, if the name contains \"Countess\", then survival seems more likely),\n",
    "    - Try to convert numeric attributes into categorical attributes: for example, different age groups had very different survival rates. So it might help to create an age category and use that instead of age. Similarly, it might be useful to have a special category for people traveling alone, since only 30% of them survived.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c24283b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Columns\n",
    "## PassengerID: Unique identifier for each passenger\n",
    "# Survived: Survival status (0 = No, 1 = Yes)\n",
    "# Pclass: Passenger class (1 = 1st, 2 = 2nd, 3 = 3rd)\n",
    "# Name: Name of the passenger\n",
    "# Sex: Gender of the passenger\n",
    "# Age: Age of the passenger in years\n",
    "# SibSp: Number of siblings or spouses aboard the Titanic\n",
    "# Parch: Number of parents or children aboard the Titanic\n",
    "# Ticket: Ticket number\n",
    "# Fare: Passenger fare\n",
    "# Cabin: Cabin number (if available)\n",
    "# Embarked: Port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0f563cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77583d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = \"data/titanic/train.csv\"\n",
    "TEST_DATA = \"data/titanic/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383b842c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(TRAIN_DATA)\n",
    "df_test = pd.read_csv(TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1350f366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 12),\n",
       "    PassengerId  Survived  Pclass  \\\n",
       " 0            1         0       3   \n",
       " 1            2         1       1   \n",
       " 2            3         1       3   \n",
       " 3            4         1       1   \n",
       " 4            5         0       3   \n",
       " \n",
       "                                                 Name     Sex   Age  SibSp  \\\n",
       " 0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       " 1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       " 2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       " 3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       " 4                           Allen, Mr. William Henry    male  35.0      0   \n",
       " \n",
       "    Parch            Ticket     Fare Cabin Embarked  \n",
       " 0      0         A/5 21171   7.2500   NaN        S  \n",
       " 1      0          PC 17599  71.2833   C85        C  \n",
       " 2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       " 3      0            113803  53.1000  C123        S  \n",
       " 4      0            373450   8.0500   NaN        S  )"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba0c119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in training data:\n",
      " Age         177\n",
      "Cabin       687\n",
      "Embarked      2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# count the number of missing values in each column\n",
    "missing_values = df_train.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "print(\"Missing values in training data:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c924a3",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ccf778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing irrelevant features\n",
    "df_train = df_train.drop(columns=['PassengerId', 'Ticket', 'Cabin'])\n",
    "df_test = df_test.drop(columns=['PassengerId', 'Ticket', 'Cabin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbb22d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embarked is a categorical feature, so we can fill missing values with the mode (most frequent value)\n",
    "df_train['Embarked'].fillna(df_train['Embarked'].mode()[0], inplace=True)\n",
    "df_test['Embarked'].fillna(df_test['Embarked'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c84451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age is a numerical feature, so we can fill missing values with the median age\n",
    "df_train['Age'].fillna(df_train['Age'].median(), inplace=True)\n",
    "df_test['Age'].fillna(df_test['Age'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0e2e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    0\n",
       "Pclass      0\n",
       "Name        0\n",
       "Sex         0\n",
       "Age         0\n",
       "SibSp       0\n",
       "Parch       0\n",
       "Fare        0\n",
       "Embarked    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f020e019",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb1d335",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['FamilySize'] = df_train['SibSp'] + df_train['Parch']\n",
    "df_test['FamilySize'] = df_test['SibSp'] + df_test['Parch']\n",
    "\n",
    "df_train['IsAlone'] = (df_train['FamilySize'] == 0).astype(int)\n",
    "df_test['IsAlone'] = (df_test['FamilySize'] == 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4ed800",
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_titles = ['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', \n",
    "               'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona']\n",
    "\n",
    "df_train['Title'] = df_train['Name'].apply(lambda name: re.search(' ([A-Za-z]+)\\.', name).group(1))\n",
    "df_test['Title'] = df_test['Name'].apply(lambda name: re.search(' ([A-Za-z]+)\\.', name).group(1))\n",
    "\n",
    "df_train['Title'] = df_train['Title'].replace(rare_titles, 'Rare')\n",
    "df_train['Title'] = df_train['Title'].replace({'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs'})\n",
    "\n",
    "df_test['Title'] = df_test['Title'].replace(rare_titles, 'Rare')\n",
    "df_test['Title'] = df_test['Title'].replace({'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b708fe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.cut: \"Bin values into discrete intervals\". (from pandas documentation)\n",
    "df_train['AgeGroup'] = pd.cut(df_train['Age'], bins=[0, 12, 18, 35, 60, 100],\n",
    "                              labels=['Child', 'Teen', 'Adult', 'MiddleAge', 'Senior'])\n",
    "df_test['AgeGroup'] = pd.cut(df_test['Age'], bins=[0, 12, 18, 35, 60, 100],\n",
    "                             labels=['Child', 'Teen', 'Adult', 'MiddleAge', 'Senior'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8789b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.qcut: \"Quantile-based discretization function\". (from pandas documentation)\n",
    "df_train['FareGroup'] = pd.qcut(df_train['Fare'], 4,\n",
    "                               labels=['LowFare', 'MidFare', 'HighFare', 'VeryHighFare'])\n",
    "df_test['FareGroup'] = pd.qcut(df_test['Fare'], 4,\n",
    "                              labels=['LowFare', 'MidFare', 'HighFare', 'VeryHighFare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adabaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing unused features\n",
    "df_train = df_train.drop(columns=['Name', 'SibSp', 'Parch', 'Age', 'Fare'])\n",
    "df_test = df_test.drop(columns=['Name', 'SibSp', 'Parch', 'Age', 'Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d569ea8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Title</th>\n",
       "      <th>AgeGroup</th>\n",
       "      <th>FareGroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Adult</td>\n",
       "      <td>LowFare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>MiddleAge</td>\n",
       "      <td>VeryHighFare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Miss</td>\n",
       "      <td>Adult</td>\n",
       "      <td>MidFare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Adult</td>\n",
       "      <td>VeryHighFare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Adult</td>\n",
       "      <td>MidFare</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex Embarked  FamilySize  IsAlone Title   AgeGroup  \\\n",
       "0         0       3    male        S           1        0    Mr      Adult   \n",
       "1         1       1  female        C           1        0   Mrs  MiddleAge   \n",
       "2         1       3  female        S           0        1  Miss      Adult   \n",
       "3         1       1  female        S           1        0   Mrs      Adult   \n",
       "4         0       3    male        S           0        1    Mr      Adult   \n",
       "\n",
       "      FareGroup  \n",
       "0       LowFare  \n",
       "1  VeryHighFare  \n",
       "2       MidFare  \n",
       "3  VeryHighFare  \n",
       "4       MidFare  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9936437",
   "metadata": {},
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90248629",
   "metadata": {},
   "source": [
    "- Why use pandas.get_dummies() instead of sklearn.preprocessing.LabelEncoder()?\n",
    "    -  pandas.get_dummies split the Embarked classes into 3 different binary columns. label encoding would have assigned a single integer to each class\n",
    "          , creating a ordinal relationship that does not exist in the data.\n",
    "    -  this is good for models that are sensitive to the scale of the features, like SVM or KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a72cccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Rare</th>\n",
       "      <th>AgeGroup_Teen</th>\n",
       "      <th>AgeGroup_Adult</th>\n",
       "      <th>AgeGroup_MiddleAge</th>\n",
       "      <th>AgeGroup_Senior</th>\n",
       "      <th>FareGroup_MidFare</th>\n",
       "      <th>FareGroup_HighFare</th>\n",
       "      <th>FareGroup_VeryHighFare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  FamilySize  IsAlone  Sex_male  Embarked_Q  Embarked_S  \\\n",
       "0         0       3           1        0         1           0           1   \n",
       "1         1       1           1        0         0           0           0   \n",
       "2         1       3           0        1         0           0           1   \n",
       "3         1       1           1        0         0           0           1   \n",
       "4         0       3           0        1         1           0           1   \n",
       "\n",
       "   Title_Miss  Title_Mr  Title_Mrs  Title_Rare  AgeGroup_Teen  AgeGroup_Adult  \\\n",
       "0           0         1          0           0              0               1   \n",
       "1           0         0          1           0              0               0   \n",
       "2           1         0          0           0              0               1   \n",
       "3           0         0          1           0              0               1   \n",
       "4           0         1          0           0              0               1   \n",
       "\n",
       "   AgeGroup_MiddleAge  AgeGroup_Senior  FareGroup_MidFare  FareGroup_HighFare  \\\n",
       "0                   0                0                  0                   0   \n",
       "1                   1                0                  0                   0   \n",
       "2                   0                0                  1                   0   \n",
       "3                   0                0                  0                   0   \n",
       "4                   0                0                  1                   0   \n",
       "\n",
       "   FareGroup_VeryHighFare  \n",
       "0                       0  \n",
       "1                       1  \n",
       "2                       0  \n",
       "3                       1  \n",
       "4                       0  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical = ['Sex', 'Embarked', 'Title', 'AgeGroup', 'FareGroup']\n",
    "\n",
    "df_train_encoded = pd.get_dummies(df_train, columns=categorical, drop_first=True)\n",
    "df_test_encoded = pd.get_dummies(df_test, columns=categorical, drop_first=True)\n",
    "\n",
    "df_train_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea124482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived              0\n",
       "Pclass                0\n",
       "FareGroup_HighFare    0\n",
       "FareGroup_MidFare     0\n",
       "AgeGroup_Senior       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_encoded.isnull().sum().sort_values(ascending=False).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b28e269",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train_encoded['Survived']\n",
    "X_train = df_train_encoded.drop(columns=['Survived'])\n",
    "\n",
    "X_test = df_test_encoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332ced66",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48bfa47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters Logistic Regression: {'C': 1, 'solver': 'lbfgs'}\n",
      "Best Accuracy: 0.8260435628648548\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "param_grid_lr = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'solver': ['liblinear', 'lbfgs']\n",
    "}\n",
    "\n",
    "grid_lr = GridSearchCV(log_reg, param_grid_lr, cv=5, scoring='accuracy')\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters Logistic Regression:\", grid_lr.best_params_)\n",
    "print(\"Best Accuracy:\", grid_lr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdef2815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters Random Forest: {'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Best Accuracy: 0.8248885820099178\n"
     ]
    }
   ],
   "source": [
    "# Random forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(rf, param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters Random Forest:\", grid_rf.best_params_)\n",
    "print(\"Best Accuracy:\", grid_rf.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "926eeec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters Gradient Boosting: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}\n",
      "Best Accuracy: 0.8249011361496453\n"
     ]
    }
   ],
   "source": [
    "# Gradient boosting\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "grid_gb = GridSearchCV(gb, param_grid_gb, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_gb.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters Gradient Boosting:\", grid_gb.best_params_)\n",
    "print(\"Best Accuracy:\", grid_gb.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "48d7a43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters KNN: {'metric': 'manhattan', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "Best Accuracy: 0.8047391877471595\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbors\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "grid_knn = GridSearchCV(knn, param_grid_knn, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_knn.fit(X_scaled, y_train)\n",
    "\n",
    "print(\"Best Parameters KNN:\", grid_knn.best_params_)\n",
    "print(\"Best Accuracy:\", grid_knn.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f9642623",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: send submission to Kaggle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pattern-recognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
